{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voluntary Problem Set\n",
    "\n",
    "This problem set allows you to play around with concepts from class and to solve some smaller problems on your own.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic: Factor Structure in Squared Returns\n",
    "\n",
    "Note: Squared Returns are ONE way to get a quick and dirty proxy for realized variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Load-in cleaned Daily log Return Data for ES 50 constituents (as used in class)\n",
    "\n",
    "Note: \n",
    "    - First observation is: January 5th 2000\n",
    "    - Last observation is:  November 12th 2020\n",
    "    - Nr of columns: 43 (42 firms and the equal-weight portfolio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Create a Pandas DataFrame of cross-sectional Variance, using Squared Daily Returns \n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "Note: \n",
    "    - First, call that object: Var_r_mth1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Visualize the Time-Series of the Annualized Market Volatility (in %)  (i.e. equal weight portfolio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D. Which Observations stand out?\n",
    "\n",
    "- 1. with regards to the peaks?\n",
    "\n",
    "- 2. with regard to whether or not vol clusters?\n",
    "\n",
    "- 3. with regard to whether vol changes abruptly or smoothly?\n",
    "\n",
    "- 4. Are the absolute magnitudes realistic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E. Which Learning Points can you extract from the previous picture about what a good model for market vol shall look like?\n",
    "\n",
    "    - 1. Market volatility is [constant / time-varying].\n",
    "    - 2. Market Volatility is driven by diffusive innovations ONLY? [yes / no]\n",
    "    - 3. Market Volatility is driven by jumpy innovations ONLY? [yes / no]\n",
    "    - 4. Market Volatility is driven by both, diffusive and jump innovations? [yes / no]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F. Plot the Volatility of VOW.DE (annualized and in %)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F.1 What is the Fundamental Event that caused Vol to go above 1400%?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F.2 Is a 1400% Vol Realistic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## G. Plot All Daily Volatilities (annualized and in %)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## G.1 Which Observations stand out?\n",
    "\n",
    "    - 1. Common and idiosyncratic moves in vol are visible? [yes | no]\n",
    "    \n",
    "    - 2. Volatility clusters? [yes | no]\n",
    "    \n",
    "    - 3. Volatility is driven by diffusive shocks with sudden upward and downward jumps? [yes | no]\n",
    "    \n",
    "    - 4. Cross-sectional vol appears to be driven by a low dimensional factor structure? [yes | no]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H. Is Daily Market Volatility Stationary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Linear Factor Structure in Cross-Sectional Variance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.1 How much Variance do each of the first 4 most important PCs explain? Round to two decimals\n",
    "\n",
    "Note: Use the variance panel from above  as the input to the PCA BUT ignore the equal weight portfolio. \n",
    "\n",
    "Variance explained of\n",
    "\n",
    "    - PC1 is []\n",
    "    \n",
    "    - PC2 is []\n",
    "    \n",
    "    - PC3 is []\n",
    "    \n",
    "    - PC4 is []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.2 Visualize the time-series of the first three PCs  \n",
    "\n",
    "Note: Create a 2x2 subplot where the time-series of market variance is on the last quadrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.3 Noteworthy Observations and Learning Points\n",
    "\n",
    "    - 1. Does the time-series of PC1 look similar to the time-series of market variance? [yes | no]\n",
    "    \n",
    "    - 2. Does the time-series of PC1 look similar to the time-series of VOW.DE's variance? [yes | no]\n",
    "    \n",
    "    - 3. How do you explain the observation?  [coincidence / unscaled data set / cannot explain]\n",
    "    \n",
    "    Hint: Read first two paragraphs of the introduction: \n",
    "    \n",
    "    https://www.ml.uni-saarland.de/code/trpca/PodSetHei-gcpr14-supp.pdf\n",
    "    \n",
    "    - 4. How to overcome this somewhat strange observation? [leave it, its fine / normalize data / erase abnormal data points]\n",
    "    \n",
    "    \n",
    "    Hint:\n",
    "    \n",
    "    https://towardsdatascience.com/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.4 How large is the correlation of PC1 with the variance of VOW.DE and the market's variance? Round to two decimals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## J. Linear Factor Structure for STANDARDIZED Cross-Sectional Variance\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "Note: Repeat the analysis from the previous Topic (\"I\") BUT use the z-score of each variance as the input to the PCA, (again: ignore the equal weight portfolio). Answer the following questions\n",
    "\n",
    "- 1. What is the correlation between PC1 and the market's variance? Round to two decimals.\n",
    "\n",
    "\n",
    "- 2. Is there support for a single-index model in cross-sectional variance, where the market's variance is the single factor? [yes / no]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K: Collection of Learning Points and Punchlines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Imprecise variance estimates [can / cannot] lead to imprecise PCs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. PCA [should / should not] be applied to normalized data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. The z-score is [one useful / the only useful] normalization scheme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Implications for a single-index model for cross-sectional variance [do / do not] change depending on whether one works with unnormalized or normalized data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. There is [weak / strong] support that cross-sectional (normalized) variance follows a single-index model with the (normalized) market variance being the single factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Roughly [30% / 70%] of variations in EU Blue Chip's (normalized) Return Variance is firm-specific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L. Cross-sectional Average of Skewness and Kurtosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L.1. How Large is the cross-sectional average of skewness and kurtosis of Return Variance (i.e. squared returns)? Round to two decimals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L.2. What are implications for parametric models of return variance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1. Strong positive skew in the variance of returns can be captured by [stochastic volatility / jumps / upward jumps] in the variance equation.\n",
    "\n",
    "- 2. Huge excess kurtosis in the variance of returns can be captured by [stochastic volatiltiy / vol in vol / upward jumps] in the variance equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M. Variance Forecast for next periods?\n",
    "\n",
    "    - 1. Can one do simple manipulations to squared returns to get forecasts of future variance? [yes / no]\n",
    "    \n",
    "    - 2. How do you evaluate the approach of fitting squared returns to an ARMA(p,q) parametrization to get variance forecasts? [optimistic / pessimistic]\n",
    "     \n",
    "    - 3. Are there variance measures with less measurement errors? [yes / no]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
